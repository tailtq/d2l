{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.05154381,  0.00966544,  0.00602048,  0.0352538 , -0.05848393,\n",
       "         0.01683447, -0.02691596, -0.002127  ,  0.00729257,  0.06459734],\n",
       "       [ 0.03342589,  0.02208288,  0.07317045,  0.02163889, -0.07724746,\n",
       "        -0.02824969, -0.04605664, -0.01612809,  0.02834059,  0.08598392]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mxnet import np, npx\n",
    "from mxnet.gluon import nn\n",
    "npx.set_np()\n",
    "\n",
    "net = nn.Sequential()\n",
    "net.add(nn.Dense(256, activation=\"relu\"))\n",
    "net.add(nn.Dense(10))\n",
    "net.initialize()\n",
    "\n",
    "X = np.random.uniform(size=(2, 20))\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Block):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden = nn.Dense(256, activation=\"relu\")\n",
    "        self.out = nn.Dense(10)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return self.out(self.hidden(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.02600484, -0.01108652,  0.05857804,  0.00879788, -0.07648174,\n",
       "         0.05120177,  0.02139943,  0.01986018, -0.05838133, -0.05440345],\n",
       "       [-0.04650507, -0.04686351,  0.10305366, -0.01742985, -0.10396324,\n",
       "         0.07541025, -0.02440178,  0.01584255, -0.09944818, -0.07798939]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net2 = MLP()\n",
    "net2.initialize()\n",
    "net2(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySequential(nn.Block):\n",
    "    def add(self, block):\n",
    "        self._children[block.name] = block\n",
    "        \n",
    "    def forward(self, X):\n",
    "        for block in self._children.values():\n",
    "            X = block(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03642648,  0.0133517 , -0.02723628, -0.02076728,  0.02490582,\n",
       "         0.00161982, -0.05942534,  0.04214321, -0.00234531,  0.00981733],\n",
       "       [ 0.03085874,  0.02843617, -0.01599898,  0.01526786,  0.01950636,\n",
       "         0.02584129, -0.07666852,  0.01154022,  0.01807711,  0.05126766]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net3 = MySequential()\n",
    "net3.add(nn.Dense(256, activation=\"relu\"))\n",
    "net3.add(nn.Dense(10))\n",
    "net3.initialize()\n",
    "net3(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FixedHiddenMLP(nn.Block):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.rand_weight = self.params.get_constant(\"rand_weight\", np.random.uniform(size=(20, 20)))\n",
    "        self.dense = nn.Dense(20, activation=\"relu\")\n",
    "        \n",
    "    def forward(self, X):\n",
    "        X = self.dense(X)\n",
    "        X = npx.relu(np.dot(X, self.rand_weight.data()) + 1)\n",
    "        X = self.dense(X)\n",
    "        \n",
    "        while np.abs(X).sum() > 1:\n",
    "            X /= 2\n",
    "            \n",
    "        return X.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0.8542471)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net4 = FixedHiddenMLP()\n",
    "net4.initialize()\n",
    "net4(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0.55749935)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NestMLP(nn.Block):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.net = nn.Sequential()\n",
    "        self.net.add(nn.Dense(64, activation=\"relu\"),\n",
    "                     nn.Dense(32, activation=\"relu\"))\n",
    "        self.dense = nn.Dense(16, activation=\"relu\")\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return self.dense(self.net(X))\n",
    "    \n",
    "chimera = nn.Sequential()\n",
    "chimera.add(NestMLP(), nn.Dense(20), FixedHiddenMLP())\n",
    "chimera.initialize()\n",
    "chimera(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParallelMLP(nn.Block):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.net1 = nn.Sequential()\n",
    "        self.net1.add(nn.Dense(64, activation=\"relu\"),\n",
    "                      nn.Dense(32, activation=\"relu\"))\n",
    "        \n",
    "        self.net2 = nn.Sequential()\n",
    "        self.net2.add(nn.Dense(128, activation=\"relu\"),\n",
    "                      nn.Dense(64, activation=\"relu\"))\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return self.net1(X), self.net2(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 32), (2, 64))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pegasus = ParallelMLP()\n",
    "pegasus.initialize()\n",
    "o1, o2 = pegasus(X)\n",
    "o1.shape, o2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End time: 0.008774042129516602\n"
     ]
    }
   ],
   "source": [
    "class FactoryMLP(nn.Block):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.net = nn.Sequential()\n",
    "        self.net.add(self.gen_block_A())\n",
    "        self.net.add(self.gen_block_A())\n",
    "        self.net.add(self.gen_block_A())\n",
    "        \n",
    "    def gen_block_A(self):\n",
    "        sequential = nn.Sequential()\n",
    "        sequential.add(nn.Dense(64, activation=\"relu\"),\n",
    "                       nn.Dense(32, activation=\"relu\"))\n",
    "        \n",
    "        return sequential\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return self.net(X)\n",
    "\n",
    "factory = FactoryMLP()\n",
    "factory.initialize()\n",
    "\n",
    "start_time = time.time()\n",
    "factory(X).shape\n",
    "print(\"End time:\", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 20)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dense50_ (\n",
       "   Parameter dense50_weight (shape=(64, 20), dtype=float32)\n",
       "   Parameter dense50_bias (shape=(64,), dtype=float32)\n",
       " ),\n",
       " dense34_ (\n",
       "   Parameter dense34_weight (shape=(256, 20), dtype=float32)\n",
       "   Parameter dense34_bias (shape=(256,), dtype=float32)\n",
       " ))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factory.net[0][0].params, net[0].params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'mxnet.gluon.parameter.Parameter'>\n",
      "Parameter dense35_bias (shape=(10,), dtype=float32)\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(type(net[1].bias))\n",
    "print(net[1].bias)\n",
    "print(net[1].bias.data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[1].weight.grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
